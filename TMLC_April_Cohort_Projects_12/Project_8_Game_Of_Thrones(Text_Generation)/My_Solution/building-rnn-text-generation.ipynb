{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:43.127266Z","iopub.execute_input":"2023-08-20T17:30:43.127669Z","iopub.status.idle":"2023-08-20T17:30:43.684768Z","shell.execute_reply.started":"2023-08-20T17:30:43.127625Z","shell.execute_reply":"2023-08-20T17:30:43.683688Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/game-of-thrones/got1.txt') as f:\n    data = f.read()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:43.687363Z","iopub.execute_input":"2023-08-20T17:30:43.687754Z","iopub.status.idle":"2023-08-20T17:30:43.705131Z","shell.execute_reply.started":"2023-08-20T17:30:43.687717Z","shell.execute_reply":"2023-08-20T17:30:43.704190Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data[:100]","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:43.707851Z","iopub.execute_input":"2023-08-20T17:30:43.708229Z","iopub.status.idle":"2023-08-20T17:30:43.716415Z","shell.execute_reply.started":"2023-08-20T17:30:43.708201Z","shell.execute_reply":"2023-08-20T17:30:43.715459Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'A Game Of Thrones \\nBook One of A Song of Ice and Fire \\nBy George R. R. Martin \\nPROLOGUE \\n\"We should '"},"metadata":{}}]},{"cell_type":"code","source":"from gensim.utils import simple_preprocess","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:43.719521Z","iopub.execute_input":"2023-08-20T17:30:43.720183Z","iopub.status.idle":"2023-08-20T17:30:43.768783Z","shell.execute_reply.started":"2023-08-20T17:30:43.720147Z","shell.execute_reply":"2023-08-20T17:30:43.767809Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data1 = simple_preprocess(data)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:43.770149Z","iopub.execute_input":"2023-08-20T17:30:43.771293Z","iopub.status.idle":"2023-08-20T17:30:44.449644Z","shell.execute_reply.started":"2023-08-20T17:30:43.771252Z","shell.execute_reply":"2023-08-20T17:30:44.448602Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"npdata1 = np.array(data1)\nlen(np.unique(npdata1)), len(npdata1)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:44.451110Z","iopub.execute_input":"2023-08-20T17:30:44.451570Z","iopub.status.idle":"2023-08-20T17:30:44.640910Z","shell.execute_reply.started":"2023-08-20T17:30:44.451533Z","shell.execute_reply":"2023-08-20T17:30:44.639923Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(11307, 284700)"},"metadata":{}}]},{"cell_type":"code","source":"data2 = ' '.join(data1)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:44.642464Z","iopub.execute_input":"2023-08-20T17:30:44.642844Z","iopub.status.idle":"2023-08-20T17:30:44.660203Z","shell.execute_reply.started":"2023-08-20T17:30:44.642809Z","shell.execute_reply":"2023-08-20T17:30:44.658306Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sequences_doc = []\nseq_len = 50\nl = seq_len + 1\ntokens = [w for w in data2.split()]\n\nfor i in range(l, len(tokens)):\n    \n    seq = tokens[i-l:i]\n\n    line = ' '.join(seq)\n    sequences_doc.append(line)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:44.661903Z","iopub.execute_input":"2023-08-20T17:30:44.662794Z","iopub.status.idle":"2023-08-20T17:30:45.436735Z","shell.execute_reply.started":"2023-08-20T17:30:44.662733Z","shell.execute_reply":"2023-08-20T17:30:45.435698Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sequences_doc[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:45.438434Z","iopub.execute_input":"2023-08-20T17:30:45.438918Z","iopub.status.idle":"2023-08-20T17:30:45.446850Z","shell.execute_reply.started":"2023-08-20T17:30:45.438863Z","shell.execute_reply":"2023-08-20T17:30:45.445953Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['game of thrones book one of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did',\n 'of thrones book one of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not',\n 'thrones book one of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise',\n 'book one of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to',\n 'one of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the',\n 'of song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the bait',\n 'song of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the bait he',\n 'of ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the bait he was',\n 'ice and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the bait he was an',\n 'and fire by george martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of smile gared did not rise to the bait he was an old']"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:45.451420Z","iopub.execute_input":"2023-08-20T17:30:45.451763Z","iopub.status.idle":"2023-08-20T17:30:45.457306Z","shell.execute_reply.started":"2023-08-20T17:30:45.451736Z","shell.execute_reply":"2023-08-20T17:30:45.456160Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(sequences_doc)\nsequences = tokenizer.texts_to_sequences(sequences_doc)\nvocab_size = len(tokenizer.word_index) + 1\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:30:45.458519Z","iopub.execute_input":"2023-08-20T17:30:45.459300Z","iopub.status.idle":"2023-08-20T17:31:09.311460Z","shell.execute_reply.started":"2023-08-20T17:30:45.459268Z","shell.execute_reply":"2023-08-20T17:31:09.310299Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"11308"},"metadata":{}}]},{"cell_type":"code","source":"sequences = np.array(sequences)\nsequences","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:09.312942Z","iopub.execute_input":"2023-08-20T17:31:09.313458Z","iopub.status.idle":"2023-08-20T17:31:11.331947Z","shell.execute_reply.started":"2023-08-20T17:31:09.313419Z","shell.execute_reply":"2023-08-20T17:31:11.330805Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[1098,    4, 1774, ...,  276, 1025,   60],\n       [   4, 1774, 1302, ..., 1025,   60,   19],\n       [1774, 1302,   46, ...,   60,   19,  909],\n       ...,\n       [   8,  192,    8, ...,   16,    1, 1699],\n       [ 192,    8,   94, ...,    1, 1699,    4],\n       [   8,   94, 3289, ..., 1699,    4,  737]])"},"metadata":{}}]},{"cell_type":"code","source":"X, y = sequences[:,:-1], sequences[:,-1]\nX,y","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:11.333459Z","iopub.execute_input":"2023-08-20T17:31:11.334635Z","iopub.status.idle":"2023-08-20T17:31:11.346208Z","shell.execute_reply.started":"2023-08-20T17:31:11.334589Z","shell.execute_reply":"2023-08-20T17:31:11.344979Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(array([[1098,    4, 1774, ...,    4,  276, 1025],\n        [   4, 1774, 1302, ...,  276, 1025,   60],\n        [1774, 1302,   46, ..., 1025,   60,   19],\n        ...,\n        [   8,  192,    8, ...,  721,   16,    1],\n        [ 192,    8,   94, ...,   16,    1, 1699],\n        [   8,   94, 3289, ...,    1, 1699,    4]]),\n array([  60,   19,  909, ..., 1699,    4,  737]))"},"metadata":{}}]},{"cell_type":"code","source":"# from tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:11.347952Z","iopub.execute_input":"2023-08-20T17:31:11.348821Z","iopub.status.idle":"2023-08-20T17:31:11.356807Z","shell.execute_reply.started":"2023-08-20T17:31:11.348782Z","shell.execute_reply":"2023-08-20T17:31:11.355775Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# y = to_categorical(y, num_classes=vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:11.358186Z","iopub.execute_input":"2023-08-20T17:31:11.358730Z","iopub.status.idle":"2023-08-20T17:31:11.366696Z","shell.execute_reply.started":"2023-08-20T17:31:11.358695Z","shell.execute_reply":"2023-08-20T17:31:11.365617Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"seq_length = X.shape[1]\nseq_length","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:11.368558Z","iopub.execute_input":"2023-08-20T17:31:11.368990Z","iopub.status.idle":"2023-08-20T17:31:11.384109Z","shell.execute_reply.started":"2023-08-20T17:31:11.368956Z","shell.execute_reply":"2023-08-20T17:31:11.383111Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:11.385392Z","iopub.execute_input":"2023-08-20T17:31:11.386430Z","iopub.status.idle":"2023-08-20T17:31:11.394920Z","shell.execute_reply.started":"2023-08-20T17:31:11.386393Z","shell.execute_reply":"2023-08-20T17:31:11.393505Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(284649,)"},"metadata":{}}]},{"cell_type":"markdown","source":"def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n    result = list()\n    in_text = seed_text\n    # generate a fixed number of words\n    for _ in range(n_words):\n    # encode the text as integer\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        # truncate sequences to a fixed length\n        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n        # predict probabilities for each word\n        yhat = model.predict(encoded, verbose=0)\n        yhat = np.argmax(yhat,axis=1)\n        print(yhat)\n        # map predicted word index to word\n        out_word = ''\n        for word, index in tokenizer.word_index.items():\n            if index == yhat:\n                out_word = word\n                break\n        # append to input\n        in_text += ' ' + out_word\n        result.append(out_word)\n    return ' '.join(result)# Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Input, dot, concatenate, Flatten\n\ndef define_model(vocab_size, seq_length):\n    # Define input layer\n    inputs = Input(shape=(seq_length,))\n    \n    # Embedding layer\n    embedding_layer = Embedding(vocab_size, 50)(inputs)\n    \n    # First LSTM layer with return_sequences=True\n    lstm_layer1 = LSTM(100, return_sequences=True)(embedding_layer)\n    \n    # Second LSTM layer with return_sequences=True\n    lstm_layer2 = LSTM(100, return_sequences=True)(lstm_layer1)\n    \n    # Attention mechanism\n    attention_scores = dot([lstm_layer2, lstm_layer1], axes=[2, 2])\n    attention_scores = tf.nn.softmax(attention_scores, axis=-1)\n    context = dot([attention_scores, lstm_layer1], axes=[2, 1])\n    \n    combined = concatenate([context, lstm_layer2])\n    \n    # Flatten the combined tensor\n    flattened = Flatten()(combined)\n    \n    # Dense layers\n    dense_layer1 = Dense(100, activation='relu')(flattened)\n    output_layer = Dense(vocab_size, activation='sigmoid')(dense_layer1)  # Output shape is (None, 1)\n    \n    # Define the model\n    model = Model(inputs=inputs, outputs=output_layer)\n    \n    # Compile the model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    # Summarize the model\n    model.summary()\n    \n    return model\n\n# Call the function to define the model\nmodel = define_model(vocab_size, seq_length)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:15:30.394962Z","iopub.execute_input":"2023-08-20T18:15:30.395400Z","iopub.status.idle":"2023-08-20T18:15:30.966450Z","shell.execute_reply.started":"2023-08-20T18:15:30.395368Z","shell.execute_reply":"2023-08-20T18:15:30.965540Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Model: \"model_9\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_10 (InputLayer)          [(None, 50)]         0           []                               \n                                                                                                  \n embedding_10 (Embedding)       (None, 50, 50)       565400      ['input_10[0][0]']               \n                                                                                                  \n lstm_18 (LSTM)                 (None, 50, 100)      60400       ['embedding_10[0][0]']           \n                                                                                                  \n lstm_19 (LSTM)                 (None, 50, 100)      80400       ['lstm_18[0][0]']                \n                                                                                                  \n dot_14 (Dot)                   (None, 50, 50)       0           ['lstm_19[0][0]',                \n                                                                  'lstm_18[0][0]']                \n                                                                                                  \n tf.nn.softmax_7 (TFOpLambda)   (None, 50, 50)       0           ['dot_14[0][0]']                 \n                                                                                                  \n dot_15 (Dot)                   (None, 50, 100)      0           ['tf.nn.softmax_7[0][0]',        \n                                                                  'lstm_18[0][0]']                \n                                                                                                  \n concatenate_7 (Concatenate)    (None, 50, 200)      0           ['dot_15[0][0]',                 \n                                                                  'lstm_19[0][0]']                \n                                                                                                  \n flatten_5 (Flatten)            (None, 10000)        0           ['concatenate_7[0][0]']          \n                                                                                                  \n dense_24 (Dense)               (None, 100)          1000100     ['flatten_5[0][0]']              \n                                                                                                  \n dense_25 (Dense)               (None, 11308)        1142108     ['dense_24[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 2,848,408\nTrainable params: 2,848,408\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:15:31.988596Z","iopub.execute_input":"2023-08-20T18:15:31.988988Z","iopub.status.idle":"2023-08-20T18:15:31.993126Z","shell.execute_reply.started":"2023-08-20T18:15:31.988956Z","shell.execute_reply":"2023-08-20T18:15:31.992278Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:13:40.346672Z","iopub.execute_input":"2023-08-20T18:13:40.347133Z","iopub.status.idle":"2023-08-20T18:13:40.354011Z","shell.execute_reply.started":"2023-08-20T18:13:40.347085Z","shell.execute_reply":"2023-08-20T18:13:40.352342Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# new_y = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:13:43.230414Z","iopub.execute_input":"2023-08-20T18:13:43.230786Z","iopub.status.idle":"2023-08-20T18:13:43.235494Z","shell.execute_reply.started":"2023-08-20T18:13:43.230755Z","shell.execute_reply":"2023-08-20T18:13:43.234460Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"y_binary = csr_matrix((np.ones(y.size), (np.arange(y.size), y)))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:15:41.978445Z","iopub.execute_input":"2023-08-20T18:15:41.978828Z","iopub.status.idle":"2023-08-20T18:15:41.997302Z","shell.execute_reply.started":"2023-08-20T18:15:41.978794Z","shell.execute_reply":"2023-08-20T18:15:41.995953Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# y = to_categorical(y, num_classes=vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:15:42.414862Z","iopub.execute_input":"2023-08-20T18:15:42.415266Z","iopub.status.idle":"2023-08-20T18:15:42.424985Z","shell.execute_reply.started":"2023-08-20T18:15:42.415234Z","shell.execute_reply":"2023-08-20T18:15:42.421733Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, batch_size=2560, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:15:42.839164Z","iopub.execute_input":"2023-08-20T18:15:42.839740Z","iopub.status.idle":"2023-08-20T18:18:14.340943Z","shell.execute_reply.started":"2023-08-20T18:15:42.839699Z","shell.execute_reply":"2023-08-20T18:18:14.339839Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Epoch 1/10\n112/112 [==============================] - 27s 200ms/step - loss: 7.0199 - accuracy: 0.0571\nEpoch 2/10\n112/112 [==============================] - 19s 165ms/step - loss: 6.6917 - accuracy: 0.0622\nEpoch 3/10\n112/112 [==============================] - 14s 126ms/step - loss: 6.6852 - accuracy: 0.0622\nEpoch 4/10\n112/112 [==============================] - 14s 125ms/step - loss: 6.6790 - accuracy: 0.0622\nEpoch 5/10\n112/112 [==============================] - 14s 122ms/step - loss: 6.6715 - accuracy: 0.0622\nEpoch 6/10\n112/112 [==============================] - 13s 118ms/step - loss: 6.6249 - accuracy: 0.0622\nEpoch 7/10\n112/112 [==============================] - 12s 111ms/step - loss: 6.5666 - accuracy: 0.0622\nEpoch 8/10\n112/112 [==============================] - 13s 116ms/step - loss: 6.5141 - accuracy: 0.0623\nEpoch 9/10\n112/112 [==============================] - 13s 114ms/step - loss: 6.4634 - accuracy: 0.0627\nEpoch 10/10\n112/112 [==============================] - 12s 110ms/step - loss: 6.3874 - accuracy: 0.0635\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ad0903a2e90>"},"metadata":{}}]},{"cell_type":"code","source":"def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n    result = list()\n    in_text = seed_text\n    # generate a fixed number of words\n    for _ in range(n_words):\n    # encode the text as integer\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        # truncate sequences to a fixed length\n        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n        # predict probabilities for each word\n        yhat = model.predict(encoded, verbose=0)\n        yhat = np.argmax(yhat,axis=1)\n        print(yhat)\n        # map predicted word index to word\n        out_word = ''\n        for word, index in tokenizer.word_index.items():\n            if index == yhat:\n                out_word = word\n                break\n        # append to input\n        in_text += ' ' + out_word\n        result.append(out_word)\n    return ' '.join(result)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:18:35.448027Z","iopub.execute_input":"2023-08-20T18:18:35.448418Z","iopub.status.idle":"2023-08-20T18:18:35.457560Z","shell.execute_reply.started":"2023-08-20T18:18:35.448387Z","shell.execute_reply":"2023-08-20T18:18:35.456412Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"pip install keras-preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:20:01.126034Z","iopub.execute_input":"2023-08-20T18:20:01.128256Z","iopub.status.idle":"2023-08-20T18:20:16.146819Z","shell.execute_reply.started":"2023-08-20T18:20:01.128206Z","shell.execute_reply":"2023-08-20T18:20:16.145307Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Collecting keras-preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-preprocessing) (1.23.5)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from keras-preprocessing) (1.16.0)\nInstalling collected packages: keras-preprocessing\nSuccessfully installed keras-preprocessing-1.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras_preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:20:16.149641Z","iopub.execute_input":"2023-08-20T18:20:16.151230Z","iopub.status.idle":"2023-08-20T18:20:16.162657Z","shell.execute_reply.started":"2023-08-20T18:20:16.151186Z","shell.execute_reply":"2023-08-20T18:20:16.161568Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"seed_text = sequences_doc[np.random.randint(0,len(sequences_doc))]\nprint(seed_text + '\\n')\ngenerate_seq(model, tokenizer, seq_length, seed_text, 50)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:20:20.931000Z","iopub.execute_input":"2023-08-20T18:20:20.931411Z","iopub.status.idle":"2023-08-20T18:20:24.771767Z","shell.execute_reply.started":"2023-08-20T18:20:20.931379Z","shell.execute_reply":"2023-08-20T18:20:24.770739Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"guiltily jory promised not to tell jory kept his word her father said with smile there are some things do not need to be told even blind man could see that wolf would never have left you willingly we had to throw rocks she said miserably told her to run to\n\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the'"},"metadata":{}}]},{"cell_type":"code","source":"seed_text = sequences_doc[np.random.randint(0,len(sequences_doc))]\nprint(seed_text + '\\n')\ngenerate_seq(model, tokenizer, seq_length, seed_text, 50)[:60]","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:21:55.119671Z","iopub.execute_input":"2023-08-20T18:21:55.120107Z","iopub.status.idle":"2023-08-20T18:21:58.301122Z","shell.execute_reply.started":"2023-08-20T18:21:55.120069Z","shell.execute_reply":"2023-08-20T18:21:58.300075Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"and stars and not before page never the darkness cried never never never inside the tent dany found cushion soft silk stuffed with feathers she clutched it to her breasts as she walked back out to drogo to her sun and stars if look back am lost it hurt even to\n\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n[1]\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"'the the the the the the the the the the the the the the the '"},"metadata":{}}]}]}